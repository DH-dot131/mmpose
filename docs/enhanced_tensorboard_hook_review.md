# EnhancedTensorBoardHook ì½”ë“œ ë¦¬ë·°

## ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œì 

### 1. Performance Overhead (ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ)

#### âŒ ë¬¸ì œì 
- **`after_train_iter`ì—ì„œ Learning Rateë¥¼ ë§¤ iterationë§ˆë‹¤ ë¡œê¹…** (Line 727-728)
  - `self.log_lr`ê°€ Trueì´ë©´ interval ì²´í¬ ì—†ì´ ë§¤ë²ˆ ì‹¤í–‰ë¨
  - ë¶ˆí•„ìš”í•œ TensorBoard write ë°œìƒ

- **Training image ë¡œê¹… ì‹œ ë§¤ë²ˆ ëª¨ë¸ ì¬ì¶”ë¡ ** (Line 385-406)
  - `model.test_step()`ì„ ë§¤ë²ˆ í˜¸ì¶œí•˜ì—¬ GPU ì—°ì‚° ì¶”ê°€
  - `train_image_interval`ì´ ì ìš©ë˜ì§€ë§Œ, ì‹¤í–‰ë  ë•Œë§ˆë‹¤ í° ì˜¤ë²„í—¤ë“œ

#### âœ… í•´ê²° ë°©ì•ˆ
```python
# Learning rateëŠ” intervalì„ ë‘ê³  ë¡œê¹…í•´ì•¼ í•¨
if self.log_lr and runner.iter % self.grad_norm_interval == 0:  # ê°™ì€ interval ì‚¬ìš©
    self._log_learning_rate(runner)
```

---

### 2. Memory Safety (ë©”ëª¨ë¦¬ ì•ˆì „ì„±)

#### âŒ ë¬¸ì œì 

**a) First batch dataë¥¼ CPUì— ë³µì‚¬í•˜ì—¬ ë©”ëª¨ë¦¬ì— ê³„ì† ìœ ì§€** (Line 714-716)
```python
self._first_batch_data = {
    'inputs': inputs.detach().cpu().clone(),  # ì „ì²´ ë°°ì¹˜ë¥¼ CPU ë©”ëª¨ë¦¬ì— ë³µì‚¬
    'data_samples': data_batch['data_samples']
}
```
- Batch sizeê°€ í¬ë©´ ìˆ˜ë°± MBì˜ CPU ë©”ëª¨ë¦¬ ì ìœ 
- í•™ìŠµ ë‚´ë‚´ ë©”ëª¨ë¦¬ì— ìœ ì§€ë¨

**b) Gradient norm ê³„ì‚° ì‹œ ë¶ˆí•„ìš”í•œ `.item()` í˜¸ì¶œ** (Line 180-188)
```python
param_norm = param.grad.data.norm(2)
total_norm += param_norm.item() ** 2  # GPU -> CPU ë™ê¸°í™”
param_norms[layer_name] = param_norm.item()  # ë˜ ë™ê¸°í™”
```
- ê° ë ˆì´ì–´ë§ˆë‹¤ GPU-CPU ë™ê¸°í™” ë°œìƒ
- ì„±ëŠ¥ ì €í•˜ ìœ ë°œ

**c) Image denormalizationì—ì„œ tensor clone í›„ in-place ì—°ì‚°** (Line 285-288)
```python
img = img_tensor.clone()
for t, m, s in zip(img, mean, std):
    t.mul_(s).add_(m)  # in-place ì—°ì‚°
```
- Cloneì€ í–ˆì§€ë§Œ ì—¬ì „íˆ ìœ„í—˜í•œ íŒ¨í„´
- ì›ë³¸ì´ í•„ìš” ì—†ìœ¼ë©´ clone ë¶ˆí•„ìš”

#### âœ… í•´ê²° ë°©ì•ˆ
```python
# 1. First batchëŠ” ì‘ì€ subsetë§Œ ì €ì¥
self._first_batch_data = {
    'inputs': inputs[:4].detach().cpu().clone(),  # 4ê°œë§Œ ì €ì¥
    'data_samples': data_batch['data_samples'][:4]
}

# 2. Gradient normì€ tensorë¡œ ê³„ì‚° í›„ í•œë²ˆë§Œ CPU ì´ë™
norms_list = []
for name, param in model.named_parameters():
    if param.grad is not None:
        norms_list.append(param.grad.data.norm(2))

if norms_list:
    norms_tensor = torch.stack(norms_list)
    total_norm = norms_tensor.norm(2).item()  # í•œ ë²ˆë§Œ ë™ê¸°í™”
```

---

### 3. DDP í˜¸í™˜ì„±

#### âŒ ë¬¸ì œì 
- **DDP wrapper ì²˜ë¦¬ê°€ ì—†ìŒ**
  - `runner.model`ì€ DDPì¼ ë•Œ `DistributedDataParallel` ê°ì²´
  - ì‹¤ì œ ëª¨ë¸ì€ `runner.model.module`ì— ìˆìŒ
  - í˜„ì¬ ì½”ë“œëŠ” DDPì—ì„œ `module` ì—†ì´ ì§ì ‘ ì ‘ê·¼

#### âœ… í•´ê²° ë°©ì•ˆ
```python
def _get_model(self, runner: Runner):
    """Get the actual model, unwrapping DDP if necessary."""
    model = runner.model
    # Unwrap DDP/FSDP wrapper
    if hasattr(model, 'module'):
        return model.module
    return model

# ì‚¬ìš© ì‹œ
def _log_gradient_norms(self, runner: Runner) -> None:
    model = self._get_model(runner)  # DDP unwrap
    for name, param in model.named_parameters():
        ...
```

---

### 4. MMEngine í˜¸í™˜ì„±

#### âš ï¸ ì£¼ì˜ ì‚¬í•­

**a) `after_val_epoch` ë©”íŠ¸ë¦­ ì „ë‹¬ ë°©ì‹** (Line 766-771)
```python
def after_val_epoch(self, runner: Runner,
                    metrics: Optional[Dict[str, float]] = None) -> None:
```
- MMEngine 1.xì—ì„œ `after_val_epoch`ëŠ” `metrics` íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì§€ ì•ŠìŒ
- MetricsëŠ” `runner.message_hub`ë¥¼ í†µí•´ ì–»ì–´ì•¼ í•¨

**b) Hook priority ë¯¸ì„¤ì •**
- ë‹¤ë¥¸ Hookê³¼ì˜ ì‹¤í–‰ ìˆœì„œê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ
- Gradient ê³„ì‚° í›„ì— ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ”ë° ë³´ì¥ë˜ì§€ ì•ŠìŒ

#### âœ… í•´ê²° ë°©ì•ˆ
```python
# MMEngine 1.x ë°©ì‹ìœ¼ë¡œ metrics ê°€ì ¸ì˜¤ê¸°
def after_val_epoch(self, runner: Runner) -> None:
    """Called after validation epoch."""
    if self.log_val_metrics:
        # Get metrics from message hub
        metrics = runner.message_hub.get_info('val')
        if metrics:
            self._log_validation_metrics(runner, metrics)

# Priority ì„¤ì •
@HOOKS.register_module()
class EnhancedTensorBoardHook(Hook):
    priority = 'VERY_LOW'  # ë‹¤ë¥¸ hook í›„ì— ì‹¤í–‰
```

---

### 5. Image Denormalization

#### âœ… í˜„ì¬ êµ¬í˜„ì€ ëŒ€ì²´ë¡œ ì •í™•í•¨
```python
def _denormalize_image(self, img_tensor: torch.Tensor, mean: tuple, std: tuple):
    img = img_tensor.clone()
    for t, m, s in zip(img, mean, std):
        t.mul_(s).add_(m)  # x = x * std + mean
    img = torch.clamp(img, 0, 1)
```

#### âš ï¸ ê°œì„  ê°€ëŠ¥í•œ ì 

**a) Mean/Std ë‹¨ìœ„ í˜¼ë™ ê°€ëŠ¥ì„±** (Line 363-371)
```python
mean = (123.675, 116.28, 103.53)  # 0-255 ë²”ìœ„
std = (58.395, 57.12, 57.375)     # 0-255 ë²”ìœ„

# 0-1 ë²”ìœ„ë¡œ ë³€í™˜
mean_norm = tuple(m / 255.0 for m in mean)
std_norm = tuple(s / 255.0 for s in std)
```
- Data preprocessorì˜ mean/stdê°€ ì´ë¯¸ 0-1 ë²”ìœ„ì¼ ìˆ˜ ìˆìŒ
- ìë™ ê°ì§€ ë¡œì§ í•„ìš”

**b) Vectorized ì—°ì‚°ìœ¼ë¡œ ìµœì í™” ê°€ëŠ¥**
```python
def _denormalize_image(self, img_tensor: torch.Tensor, mean: tuple, std: tuple):
    """Denormalize image tensor to numpy array."""
    # Vectorized operation (ë” ë¹ ë¦„)
    mean_tensor = torch.tensor(mean, device=img_tensor.device).view(3, 1, 1)
    std_tensor = torch.tensor(std, device=img_tensor.device).view(3, 1, 1)

    img = img_tensor * std_tensor + mean_tensor
    img = torch.clamp(img, 0, 1)

    img_np = img.permute(1, 2, 0).cpu().numpy()
    img_np = (img_np * 255).astype(np.uint8)
    return img_np
```

---

## ì¶”ê°€ ë°œê²¬ ì‚¬í•­

### 6. ì¤‘ë³µ ì½”ë“œ
- `_init_tensorboard_writer`ì™€ `_get_tensorboard_writer`ê°€ ê±°ì˜ ë™ì¼ (Line 98-162)
- `_init_tensorboard_writer`ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

### 7. Error Handling ë¬¸ì œ
```python
except Exception as e:
    import traceback
    traceback.print_exc()
    pass  # ì—ëŸ¬ë¥¼ ì‚¼í‚´
```
- ì—ëŸ¬ë¥¼ printë§Œ í•˜ê³  ë¬´ì‹œí•¨
- ë””ë²„ê¹… ì–´ë ¤ì›€
- ìµœì†Œí•œ ë¡œê¹…í•´ì•¼ í•¨

### 8. Validation image ë§¤ iteration ë¡œê¹…
- `val_image_interval=1`ì´ default
- Validationì€ ë³´í†µ ìˆ˜ë°±~ìˆ˜ì²œ iteration
- ë””ìŠ¤í¬ I/O í­ë°œ

---

## ìš°ì„ ìˆœìœ„ë³„ ìˆ˜ì • ê¶Œì¥ì‚¬í•­

### ğŸ”´ Critical (ì¦‰ì‹œ ìˆ˜ì • í•„ìš”)
1. DDP wrapper ì²˜ë¦¬ ì¶”ê°€
2. Learning rate interval ì²´í¬ ì¶”ê°€
3. MMEngine `after_val_epoch` ì‹œê·¸ë‹ˆì²˜ ìˆ˜ì •

### ğŸŸ¡ Important (ê°œì„  í•„ìš”)
4. First batch data ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
5. Gradient norm ê³„ì‚° ìµœì í™”
6. Validation image interval default ê°’ ì¦ê°€ (1 -> 10)

### ğŸŸ¢ Nice to have (ì„ íƒì  ê°œì„ )
7. Image denormalization vectorization
8. ì¤‘ë³µ ì½”ë“œ ì œê±°
9. Error logging ê°œì„ 
10. Mean/Std ìë™ ê°ì§€

---

## ì„±ëŠ¥ ì˜í–¥ ë¶„ì„

| ê¸°ëŠ¥ | í˜„ì¬ ì˜¤ë²„í—¤ë“œ | ê°œì„  í›„ ì˜¤ë²„í—¤ë“œ |
|------|--------------|------------------|
| Learning rate logging | ë§¤ iter (~0.1ms) | 100 iterë§ˆë‹¤ (~0.001ms/iter) |
| Gradient norms | ~5-10ms (GPU ë™ê¸°í™”) | ~1-2ms (ìµœì í™” í›„) |
| Training images | ~100-500ms (ì¬ì¶”ë¡ ) | ~50-100ms (outputs ì¬ì‚¬ìš©) |
| Weight histograms | ~50-100ms | ~30-50ms (ìƒ˜í”Œë§) |
| First batch storage | ìˆ˜ë°± MB RAM | ~10-50 MB (4ê°œë§Œ ì €ì¥) |

---

## í…ŒìŠ¤íŠ¸ ê¶Œì¥ì‚¬í•­

1. **DDP í™˜ê²½ í…ŒìŠ¤íŠ¸**
   ```bash
   torchrun --nproc_per_node=2 train.py
   ```

2. **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§**
   ```python
   import torch.cuda
   torch.cuda.memory_summary()
   ```

3. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
   - Hook í™œì„±í™” ì „/í›„ iteration time ë¹„êµ
   - TensorBoard íŒŒì¼ í¬ê¸° ëª¨ë‹ˆí„°ë§
